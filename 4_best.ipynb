{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LTH_helper import LTH\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import optimizers, initializers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow_model_optimization.sparsity.keras import prune_low_magnitude, ConstantSparsity, strip_pruning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "X = train_images.reshape(-1, 784)/255\n",
    "y = train_labels.reshape(-1, 1)\n",
    "X_test = test_images.reshape(-1, 784)/255\n",
    "y_test = test_labels.reshape(-1, 1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, lr=0.001):\n",
    "    optim = optimizers.Adam(lr=lr)\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    \n",
    "def get_model(compile_model_flag=True, lr=0.001):\n",
    "    reduce = 2\n",
    "    input_dim=784\n",
    "    output_size = 10\n",
    "#     initializer = initializers.RandomNormal(mean=0, stddev=0.1)\n",
    "    initializer = initializers.glorot_normal()\n",
    "    # Creo el modelo\n",
    "    model = Sequential()\n",
    "    model.add(Dense(784*2//reduce, activation='relu', \n",
    "                    name='hidden_1', \n",
    "                    kernel_initializer=initializer,\n",
    "                    input_dim=input_dim))\n",
    "    model.add(Dense(784//reduce, activation='relu', \n",
    "                    name='hidden_2', \n",
    "                    kernel_initializer=initializer))\n",
    "    model.add(Dense(output_size, activation='softmax', \n",
    "                    name='Salida', \n",
    "                    kernel_initializer=initializer))\n",
    "    if compile_model_flag:\n",
    "        compile_model(model, lr=lr)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lth = LTH(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(filename):\n",
    "    return [\n",
    "#         ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=np.sqrt(0.1), patience=10, verbose=1, min_lr=1e-4),\n",
    "        ModelCheckpoint(filepath=filename,  verbose=1, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lth = LTH(get_model)\n",
    "pruned_model = lth.get_prunned_model('best_untrained/best_untrained_acc_27.9_81.3_not_sparse.hdf5', pm=0.27933673469387754)\n",
    "compile_model(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_low_magnitude_hidden_1: 0.7206632653061225, 0.27933673469387754\n",
      "prune_low_magnitude_hidden_2: 0.7206632653061225, 0.27933673469387754\n",
      "prune_low_magnitude_Salida: 0.7206632653061225, 0.27933673469387754\n"
     ]
    }
   ],
   "source": [
    "lth.test_model_sparsity(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.89278, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 3s - loss: 0.2281 - accuracy: 0.9148 - val_loss: 0.2910 - val_accuracy: 0.8928\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.89278 to 0.89300, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 3s - loss: 0.2011 - accuracy: 0.9246 - val_loss: 0.2933 - val_accuracy: 0.8930\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.89300 to 0.89900, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 3s - loss: 0.1901 - accuracy: 0.9277 - val_loss: 0.2796 - val_accuracy: 0.8990\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.89900 to 0.89933, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 3s - loss: 0.1805 - accuracy: 0.9330 - val_loss: 0.2895 - val_accuracy: 0.8993\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.89933\n",
      "200/200 - 3s - loss: 0.1680 - accuracy: 0.9374 - val_loss: 0.2964 - val_accuracy: 0.8959\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.89933\n",
      "200/200 - 3s - loss: 0.1588 - accuracy: 0.9405 - val_loss: 0.2964 - val_accuracy: 0.8971\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.89933 to 0.90067, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 3s - loss: 0.1515 - accuracy: 0.9433 - val_loss: 0.2934 - val_accuracy: 0.9007\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.90067\n",
      "200/200 - 3s - loss: 0.1449 - accuracy: 0.9461 - val_loss: 0.2964 - val_accuracy: 0.8998\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.90067\n",
      "200/200 - 3s - loss: 0.1374 - accuracy: 0.9486 - val_loss: 0.3019 - val_accuracy: 0.8992\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.90067\n",
      "200/200 - 3s - loss: 0.1286 - accuracy: 0.9521 - val_loss: 0.3163 - val_accuracy: 0.8978\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 256\n",
    "# Save initial weights\n",
    "history = pruned_model.fit(X_train, \n",
    "           y_train,\n",
    "           epochs=epochs, batch_size=batch_size, \n",
    "           validation_data = (X_val, y_val),\n",
    "           verbose=2, \n",
    "           callbacks=get_callbacks('mlp.mnist.first_train.hdf5')\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_low_magnitude_hidden_1: 0.7206632653061225, 0.27933673469387754\n",
      "prune_low_magnitude_hidden_2: 0.7206632653061225, 0.27933673469387754\n",
      "prune_low_magnitude_Salida: 0.7206632653061225, 0.27933673469387754\n"
     ]
    }
   ],
   "source": [
    "lth.test_model_sparsity(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2] *",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

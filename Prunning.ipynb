{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -q tensorflow-model-optimization\n",
    "#! pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LTH_helper import LTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1803.03635\n",
    "\n",
    "https://www.youtube.com/watch?v=0VH1Lim8gL8&feature=youtu.be&t=2760"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "import os\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    np.random.seed(seed)\n",
    "    rn.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    # session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    # sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    # K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21a1ba1a316bb0a6f5d8f85d86b3ba2307f125af"
   },
   "source": [
    "# Cargo datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7720949cd52b1de2d7687500e3d121f30bc80f82"
   },
   "outputs": [],
   "source": [
    "X = np.load(folder+'train_images.npy').reshape(-1, 784)/255\n",
    "y = np.loadtxt(folder+'train_labels.csv', delimiter=',', skiprows=1).reshape(-1, 1)\n",
    "X_test = np.load(folder+'test_images.npy').reshape(-1, 784)/255\n",
    "y_test = pd.read_csv(folder+'test_labels.csv')['Category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f987cc26468c6d17e63a953827437abb66da4383"
   },
   "source": [
    "# Red neuronal b√°sica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, lr=0.001):\n",
    "    optim = optimizers.Adam(lr=lr)\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "6e998b9f383e967a21d0ee6a89dfc8fec72d7f80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_1 (Dense)             (None, 1568)              1230880   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "hidden_2 (Dense)             (None, 784)               1230096   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Salida (Dense)               (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,468,826\n",
      "Trainable params: 2,468,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(compile_model_flag=True, lr=0.001):\n",
    "    input_dim=784\n",
    "    output_size = 10\n",
    "    # Creo el modelo\n",
    "    model = Sequential()\n",
    "    model.add(Dense(784*2, activation='linear', name='hidden_1', input_dim=input_dim))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(784, activation='linear', name='hidden_2'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(output_size, name='Salida'))\n",
    "    model.add(Activation('softmax'))\n",
    "    if compile_model_flag:\n",
    "        compile_model(model, lr=lr)\n",
    "    return model\n",
    "model = get_model()\n",
    "# model.save_weights('random-init.hdf5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lth = LTH(get_model, compile_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(filename):\n",
    "    return [\n",
    "        ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=np.sqrt(0.1), patience=10, verbose=1, min_lr=1e-4),\n",
    "        ModelCheckpoint(filepath=filename,  verbose=1, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "bac8f7a2f7fb157ec21445359a6f316073515ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/96\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.84467, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.5001 - accuracy: 0.8203 - val_loss: 0.4198 - val_accuracy: 0.8447 - lr: 0.0010\n",
      "Epoch 2/96\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.84467 to 0.86889, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 0s - loss: 0.3498 - accuracy: 0.8717 - val_loss: 0.3537 - val_accuracy: 0.8689 - lr: 0.0010\n",
      "Epoch 3/96\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.86889\n",
      "200/200 - 0s - loss: 0.3130 - accuracy: 0.8828 - val_loss: 0.3678 - val_accuracy: 0.8591 - lr: 0.0010\n",
      "Epoch 4/96\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.86889 to 0.87989, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.2922 - accuracy: 0.8915 - val_loss: 0.3204 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Epoch 5/96\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.87989\n",
      "200/200 - 0s - loss: 0.2709 - accuracy: 0.8994 - val_loss: 0.3334 - val_accuracy: 0.8770 - lr: 0.0010\n",
      "Epoch 6/96\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.87989 to 0.88489, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.2568 - accuracy: 0.9040 - val_loss: 0.3136 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Epoch 7/96\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.88489\n",
      "200/200 - 0s - loss: 0.2408 - accuracy: 0.9093 - val_loss: 0.3186 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Epoch 8/96\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.88489\n",
      "200/200 - 1s - loss: 0.2336 - accuracy: 0.9117 - val_loss: 0.3335 - val_accuracy: 0.8804 - lr: 0.0010\n",
      "Epoch 9/96\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.88489 to 0.88789, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.2205 - accuracy: 0.9170 - val_loss: 0.3207 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Epoch 10/96\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.88789 to 0.89000, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.2137 - accuracy: 0.9178 - val_loss: 0.3238 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 11/96\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.89000 to 0.89278, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.2008 - accuracy: 0.9251 - val_loss: 0.3104 - val_accuracy: 0.8928 - lr: 0.0010\n",
      "Epoch 12/96\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.89278\n",
      "200/200 - 1s - loss: 0.1963 - accuracy: 0.9257 - val_loss: 0.3375 - val_accuracy: 0.8862 - lr: 0.0010\n",
      "Epoch 13/96\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.89278\n",
      "200/200 - 0s - loss: 0.1847 - accuracy: 0.9296 - val_loss: 0.3181 - val_accuracy: 0.8918 - lr: 0.0010\n",
      "Epoch 14/96\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.89278\n",
      "200/200 - 0s - loss: 0.1778 - accuracy: 0.9317 - val_loss: 0.3101 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 15/96\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.89278 to 0.89667, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.1673 - accuracy: 0.9361 - val_loss: 0.3147 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 16/96\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.89667\n",
      "200/200 - 1s - loss: 0.1600 - accuracy: 0.9398 - val_loss: 0.3401 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Epoch 17/96\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.89667\n",
      "200/200 - 0s - loss: 0.1555 - accuracy: 0.9404 - val_loss: 0.3322 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Epoch 18/96\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.89667\n",
      "200/200 - 1s - loss: 0.1496 - accuracy: 0.9420 - val_loss: 0.3499 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Epoch 19/96\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.89667\n",
      "200/200 - 1s - loss: 0.1368 - accuracy: 0.9480 - val_loss: 0.3667 - val_accuracy: 0.8888 - lr: 0.0010\n",
      "Epoch 20/96\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.89667\n",
      "200/200 - 0s - loss: 0.1356 - accuracy: 0.9473 - val_loss: 0.3378 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 21/96\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.89667\n",
      "200/200 - 1s - loss: 0.1335 - accuracy: 0.9474 - val_loss: 0.3359 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Epoch 22/96\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.89667\n",
      "200/200 - 0s - loss: 0.1255 - accuracy: 0.9502 - val_loss: 0.3852 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 23/96\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.89667\n",
      "200/200 - 1s - loss: 0.1224 - accuracy: 0.9537 - val_loss: 0.3672 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Epoch 24/96\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.89667\n",
      "200/200 - 1s - loss: 0.1203 - accuracy: 0.9528 - val_loss: 0.3711 - val_accuracy: 0.8952 - lr: 0.0010\n",
      "Epoch 25/96\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00031622778103685084.\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.89667\n",
      "200/200 - 1s - loss: 0.1139 - accuracy: 0.9562 - val_loss: 0.3664 - val_accuracy: 0.8944 - lr: 0.0010\n",
      "Epoch 26/96\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.89667 to 0.90500, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.0743 - accuracy: 0.9717 - val_loss: 0.3718 - val_accuracy: 0.9050 - lr: 3.1623e-04\n",
      "Epoch 27/96\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.90500\n",
      "200/200 - 1s - loss: 0.0650 - accuracy: 0.9761 - val_loss: 0.3770 - val_accuracy: 0.9040 - lr: 3.1623e-04\n",
      "Epoch 28/96\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.90500 to 0.90733, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.0602 - accuracy: 0.9781 - val_loss: 0.3801 - val_accuracy: 0.9073 - lr: 3.1623e-04\n",
      "Epoch 29/96\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.90733\n",
      "200/200 - 1s - loss: 0.0575 - accuracy: 0.9786 - val_loss: 0.3966 - val_accuracy: 0.9057 - lr: 3.1623e-04\n",
      "Epoch 30/96\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.90733 to 0.90811, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.0544 - accuracy: 0.9798 - val_loss: 0.4022 - val_accuracy: 0.9081 - lr: 3.1623e-04\n",
      "Epoch 31/96\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0500 - accuracy: 0.9821 - val_loss: 0.4128 - val_accuracy: 0.9058 - lr: 3.1623e-04\n",
      "Epoch 32/96\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0485 - accuracy: 0.9825 - val_loss: 0.4115 - val_accuracy: 0.9056 - lr: 3.1623e-04\n",
      "Epoch 33/96\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0452 - accuracy: 0.9840 - val_loss: 0.4398 - val_accuracy: 0.9024 - lr: 3.1623e-04\n",
      "Epoch 34/96\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0443 - accuracy: 0.9843 - val_loss: 0.4368 - val_accuracy: 0.9037 - lr: 3.1623e-04\n",
      "Epoch 35/96\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0407 - accuracy: 0.9856 - val_loss: 0.4567 - val_accuracy: 0.9049 - lr: 3.1623e-04\n",
      "Epoch 36/96\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0382 - accuracy: 0.9862 - val_loss: 0.4561 - val_accuracy: 0.9022 - lr: 3.1623e-04\n",
      "Epoch 37/96\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0369 - accuracy: 0.9874 - val_loss: 0.4520 - val_accuracy: 0.9063 - lr: 3.1623e-04\n",
      "Epoch 38/96\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0334 - accuracy: 0.9886 - val_loss: 0.4775 - val_accuracy: 0.9042 - lr: 3.1623e-04\n",
      "Epoch 39/96\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0328 - accuracy: 0.9889 - val_loss: 0.4846 - val_accuracy: 0.9038 - lr: 3.1623e-04\n",
      "Epoch 40/96\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00010000000639606199.\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0293 - accuracy: 0.9904 - val_loss: 0.5084 - val_accuracy: 0.9062 - lr: 3.1623e-04\n",
      "Epoch 41/96\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.5012 - val_accuracy: 0.9053 - lr: 1.0000e-04\n",
      "Epoch 42/96\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0175 - accuracy: 0.9955 - val_loss: 0.5152 - val_accuracy: 0.9059 - lr: 1.0000e-04\n",
      "Epoch 43/96\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0165 - accuracy: 0.9961 - val_loss: 0.5223 - val_accuracy: 0.9056 - lr: 1.0000e-04\n",
      "Epoch 44/96\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.5267 - val_accuracy: 0.9034 - lr: 1.0000e-04\n",
      "Epoch 45/96\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.5285 - val_accuracy: 0.9046 - lr: 1.0000e-04\n",
      "Epoch 46/96\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0150 - accuracy: 0.9964 - val_loss: 0.5346 - val_accuracy: 0.9054 - lr: 1.0000e-04\n",
      "Epoch 47/96\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0144 - accuracy: 0.9968 - val_loss: 0.5413 - val_accuracy: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 48/96\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.5484 - val_accuracy: 0.9059 - lr: 1.0000e-04\n",
      "Epoch 49/96\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0130 - accuracy: 0.9973 - val_loss: 0.5593 - val_accuracy: 0.9038 - lr: 1.0000e-04\n",
      "Epoch 50/96\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.5615 - val_accuracy: 0.9051 - lr: 1.0000e-04\n",
      "Epoch 51/96\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0117 - accuracy: 0.9977 - val_loss: 0.5661 - val_accuracy: 0.9081 - lr: 1.0000e-04\n",
      "Epoch 52/96\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0111 - accuracy: 0.9981 - val_loss: 0.5751 - val_accuracy: 0.9049 - lr: 1.0000e-04\n",
      "Epoch 53/96\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.5796 - val_accuracy: 0.9051 - lr: 1.0000e-04\n",
      "Epoch 54/96\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0105 - accuracy: 0.9981 - val_loss: 0.5940 - val_accuracy: 0.9038 - lr: 1.0000e-04\n",
      "Epoch 55/96\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0100 - accuracy: 0.9983 - val_loss: 0.5978 - val_accuracy: 0.9030 - lr: 1.0000e-04\n",
      "Epoch 56/96\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.6092 - val_accuracy: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 57/96\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0087 - accuracy: 0.9987 - val_loss: 0.6161 - val_accuracy: 0.9041 - lr: 1.0000e-04\n",
      "Epoch 58/96\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0087 - accuracy: 0.9987 - val_loss: 0.6106 - val_accuracy: 0.9062 - lr: 1.0000e-04\n",
      "Epoch 59/96\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.6163 - val_accuracy: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 60/96\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.6323 - val_accuracy: 0.9046 - lr: 1.0000e-04\n",
      "Epoch 61/96\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.6371 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
      "Epoch 62/96\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.6415 - val_accuracy: 0.9056 - lr: 1.0000e-04\n",
      "Epoch 63/96\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.6547 - val_accuracy: 0.9039 - lr: 1.0000e-04\n",
      "Epoch 64/96\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.6605 - val_accuracy: 0.9034 - lr: 1.0000e-04\n",
      "Epoch 65/96\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.6663 - val_accuracy: 0.9041 - lr: 1.0000e-04\n",
      "Epoch 66/96\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.6674 - val_accuracy: 0.9046 - lr: 1.0000e-04\n",
      "Epoch 67/96\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.6821 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 68/96\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.6872 - val_accuracy: 0.9044 - lr: 1.0000e-04\n",
      "Epoch 69/96\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.7140 - val_accuracy: 0.9041 - lr: 1.0000e-04\n",
      "Epoch 70/96\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.6892 - val_accuracy: 0.9044 - lr: 1.0000e-04\n",
      "Epoch 71/96\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.7081 - val_accuracy: 0.9039 - lr: 1.0000e-04\n",
      "Epoch 72/96\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.7151 - val_accuracy: 0.9044 - lr: 1.0000e-04\n",
      "Epoch 73/96\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.7275 - val_accuracy: 0.9016 - lr: 1.0000e-04\n",
      "Epoch 74/96\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.7303 - val_accuracy: 0.9050 - lr: 1.0000e-04\n",
      "Epoch 75/96\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.7208 - val_accuracy: 0.9049 - lr: 1.0000e-04\n",
      "Epoch 76/96\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.7459 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 77/96\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.7509 - val_accuracy: 0.9043 - lr: 1.0000e-04\n",
      "Epoch 78/96\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.7553 - val_accuracy: 0.9047 - lr: 1.0000e-04\n",
      "Epoch 79/96\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.7625 - val_accuracy: 0.9043 - lr: 1.0000e-04\n",
      "Epoch 80/96\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.7651 - val_accuracy: 0.9044 - lr: 1.0000e-04\n",
      "Epoch 81/96\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.7679 - val_accuracy: 0.9038 - lr: 1.0000e-04\n",
      "Epoch 82/96\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.7674 - val_accuracy: 0.9046 - lr: 1.0000e-04\n",
      "Epoch 83/96\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.7684 - val_accuracy: 0.9040 - lr: 1.0000e-04\n",
      "Epoch 84/96\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.7738 - val_accuracy: 0.9041 - lr: 1.0000e-04\n",
      "Epoch 85/96\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7883 - val_accuracy: 0.9038 - lr: 1.0000e-04\n",
      "Epoch 86/96\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7919 - val_accuracy: 0.9030 - lr: 1.0000e-04\n",
      "Epoch 87/96\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8069 - val_accuracy: 0.9032 - lr: 1.0000e-04\n",
      "Epoch 88/96\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8034 - val_accuracy: 0.9039 - lr: 1.0000e-04\n",
      "Epoch 89/96\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8148 - val_accuracy: 0.9021 - lr: 1.0000e-04\n",
      "Epoch 90/96\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8177 - val_accuracy: 0.9032 - lr: 1.0000e-04\n",
      "Epoch 91/96\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.8128 - val_accuracy: 0.9019 - lr: 1.0000e-04\n",
      "Epoch 92/96\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.8076 - val_accuracy: 0.9039 - lr: 1.0000e-04\n",
      "Epoch 93/96\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8235 - val_accuracy: 0.9028 - lr: 1.0000e-04\n",
      "Epoch 94/96\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.90811\n",
      "200/200 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8308 - val_accuracy: 0.9024 - lr: 1.0000e-04\n",
      "Epoch 95/96\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 9.7472e-04 - accuracy: 1.0000 - val_loss: 0.8291 - val_accuracy: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 96/96\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.90811\n",
      "200/200 - 0s - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.8280 - val_accuracy: 0.9031 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "set_random_seeds(42)\n",
    "model = get_model()\n",
    "\n",
    "# Save initial weights\n",
    "model.save_weights('mlp.mnist.initial_weights.hdf5')\n",
    "history = model.fit(X_train, \n",
    "           y_train,\n",
    "           epochs=epochs, batch_size=batch_size, \n",
    "           validation_data = (X_val, y_val),\n",
    "           verbose=2, \n",
    "           callbacks=get_callbacks('mlp.mnist.first_train.hdf5')\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8279619216918945, 0.9031111001968384]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val, y_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4022064208984375, 0.9081110954284668] [0.45946744084358215, 0.9025999903678894]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('mlp.mnist.first_train.hdf5')\n",
    "print(model.evaluate(X_val, y_val, verbose=0), model.evaluate(X_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = 0.50\n",
    "# pm**(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hidden_1', 'activation_3', 'hidden_2', 'activation_4', 'Salida', 'activation_5']\n"
     ]
    }
   ],
   "source": [
    "print([layer.name for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/usuario/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:199: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "layers_to_pune = ['hidden_1', 'hidden_2', 'Salida']\n",
    "model_pruned_layers_trained = lth.get_prunned_model('mlp.mnist.first_train.hdf5', layers_to_pune, X_train, y_train, pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 856us/step - loss: 0.4112 - accuracy: 0.8986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4111524820327759, 0.8985999822616577]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pruned_layers_trained.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 870us/step - loss: 0.4112 - accuracy: 0.8986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4111524820327759, 0.8985999822616577]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_initialized = lth.initialize_sparse_model('mlp.mnist.first_train.hdf5', model_pruned_layers_trained, pm)\n",
    "model_initialized.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_low_magnitude_hidden_1: True, shape: (784, 1568), sparcity: 0.5\n",
      "prune_low_magnitude_hidden_2: True, shape: (1568, 784), sparcity: 0.5\n",
      "prune_low_magnitude_Salida: True, shape: (784, 10), sparcity: 0.5\n"
     ]
    }
   ],
   "source": [
    "lth.verify_mask_with_model_min_weights('mlp.mnist.first_train.hdf5', model_pruned_layers_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_low_magnitude_hidden_1: False, shape: (784, 1568), sparcity: 0.5\n",
      "prune_low_magnitude_hidden_2: False, shape: (1568, 784), sparcity: 0.5\n",
      "prune_low_magnitude_Salida: False, shape: (784, 10), sparcity: 0.5\n"
     ]
    }
   ],
   "source": [
    "# It has to be false beacuase the model is not trained\n",
    "lth.verify_mask_with_model_min_weights('mlp.mnist.initial_weights.hdf5', model_pruned_layers_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize prunned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = lth.initialize_sparse_model('mlp.mnist.initial_weights.hdf5', model_pruned_layers_trained, pm)\n",
    "lth.compile_model(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_low_magnitude_hidden_1: True, shape: (784, 1568), sparcity: 0.5\n",
      "prune_low_magnitude_hidden_2: True, shape: (1568, 784), sparcity: 0.5\n",
      "prune_low_magnitude_Salida: True, shape: (784, 10), sparcity: 0.5\n"
     ]
    }
   ],
   "source": [
    "lth.verify_mask_with_model_min_weights(pruned_model, model_pruned_layers_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train prunned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prunned_callbacks(filename):\n",
    "    return get_callbacks(filename) + [tfmot.sparsity.keras.UpdatePruningStep()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/96\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85678, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.4518 - accuracy: 0.8460 - val_loss: 0.3879 - val_accuracy: 0.8568 - lr: 0.0010\n",
      "Epoch 2/96\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.85678 to 0.87644, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.2995 - accuracy: 0.8907 - val_loss: 0.3374 - val_accuracy: 0.8764 - lr: 0.0010\n",
      "Epoch 3/96\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.87644\n",
      "200/200 - 1s - loss: 0.2629 - accuracy: 0.9018 - val_loss: 0.3381 - val_accuracy: 0.8738 - lr: 0.0010\n",
      "Epoch 4/96\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.87644 to 0.88678, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.2400 - accuracy: 0.9103 - val_loss: 0.3117 - val_accuracy: 0.8868 - lr: 0.0010\n",
      "Epoch 5/96\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.88678\n",
      "200/200 - 1s - loss: 0.2186 - accuracy: 0.9187 - val_loss: 0.3127 - val_accuracy: 0.8858 - lr: 0.0010\n",
      "Epoch 6/96\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.88678 to 0.89356, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.2055 - accuracy: 0.9223 - val_loss: 0.3051 - val_accuracy: 0.8936 - lr: 0.0010\n",
      "Epoch 7/96\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.89356 to 0.89589, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.1893 - accuracy: 0.9292 - val_loss: 0.2990 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Epoch 8/96\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.89589 to 0.89633, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.1779 - accuracy: 0.9333 - val_loss: 0.3036 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 9/96\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.89633\n",
      "200/200 - 1s - loss: 0.1659 - accuracy: 0.9380 - val_loss: 0.3065 - val_accuracy: 0.8962 - lr: 0.0010\n",
      "Epoch 10/96\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.89633\n",
      "200/200 - 1s - loss: 0.1666 - accuracy: 0.9369 - val_loss: 0.3205 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 11/96\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.89633\n",
      "200/200 - 1s - loss: 0.1480 - accuracy: 0.9435 - val_loss: 0.3316 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 12/96\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.89633\n",
      "200/200 - 1s - loss: 0.1441 - accuracy: 0.9453 - val_loss: 0.3360 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Epoch 13/96\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.89633\n",
      "200/200 - 1s - loss: 0.1345 - accuracy: 0.9477 - val_loss: 0.3421 - val_accuracy: 0.8948 - lr: 0.0010\n",
      "Epoch 14/96\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.89633 to 0.89700, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.1293 - accuracy: 0.9508 - val_loss: 0.3183 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 15/96\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.89700 to 0.89722, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.1164 - accuracy: 0.9554 - val_loss: 0.3428 - val_accuracy: 0.8972 - lr: 0.0010\n",
      "Epoch 16/96\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.89722\n",
      "200/200 - 1s - loss: 0.1125 - accuracy: 0.9575 - val_loss: 0.3718 - val_accuracy: 0.8944 - lr: 0.0010\n",
      "Epoch 17/96\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.89722\n",
      "200/200 - 1s - loss: 0.1105 - accuracy: 0.9574 - val_loss: 0.3860 - val_accuracy: 0.8934 - lr: 0.0010\n",
      "Epoch 18/96\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.89722\n",
      "200/200 - 1s - loss: 0.1111 - accuracy: 0.9575 - val_loss: 0.3737 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 19/96\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.89722\n",
      "200/200 - 1s - loss: 0.0971 - accuracy: 0.9630 - val_loss: 0.4002 - val_accuracy: 0.8914 - lr: 0.0010\n",
      "Epoch 20/96\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.89722 to 0.89733, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.0938 - accuracy: 0.9641 - val_loss: 0.3838 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Epoch 21/96\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.89733\n",
      "200/200 - 1s - loss: 0.0956 - accuracy: 0.9631 - val_loss: 0.3686 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 22/96\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.89733 to 0.90144, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.0834 - accuracy: 0.9678 - val_loss: 0.3985 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 23/96\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.90144\n",
      "200/200 - 1s - loss: 0.0811 - accuracy: 0.9696 - val_loss: 0.4187 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Epoch 24/96\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.90144\n",
      "200/200 - 1s - loss: 0.0799 - accuracy: 0.9702 - val_loss: 0.4095 - val_accuracy: 0.8954 - lr: 0.0010\n",
      "Epoch 25/96\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.90144\n",
      "200/200 - 1s - loss: 0.0768 - accuracy: 0.9715 - val_loss: 0.4172 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 26/96\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.90144\n",
      "200/200 - 1s - loss: 0.0682 - accuracy: 0.9738 - val_loss: 0.4367 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 27/96\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.90144\n",
      "200/200 - 1s - loss: 0.0714 - accuracy: 0.9725 - val_loss: 0.4516 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 28/96\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.90144\n",
      "200/200 - 1s - loss: 0.0634 - accuracy: 0.9757 - val_loss: 0.4293 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 29/96\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.90144\n",
      "200/200 - 1s - loss: 0.0692 - accuracy: 0.9741 - val_loss: 0.4594 - val_accuracy: 0.8954 - lr: 0.0010\n",
      "Epoch 30/96\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.90144\n",
      "200/200 - 1s - loss: 0.0603 - accuracy: 0.9777 - val_loss: 0.4679 - val_accuracy: 0.9002 - lr: 0.0010\n",
      "Epoch 31/96\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.90144\n",
      "200/200 - 1s - loss: 0.0606 - accuracy: 0.9776 - val_loss: 0.4741 - val_accuracy: 0.8950 - lr: 0.0010\n",
      "Epoch 32/96\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00031622778103685084.\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.90144\n",
      "200/200 - 1s - loss: 0.0563 - accuracy: 0.9790 - val_loss: 0.4671 - val_accuracy: 0.8984 - lr: 0.0010\n",
      "Epoch 33/96\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.90144 to 0.90444, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.0279 - accuracy: 0.9911 - val_loss: 0.4758 - val_accuracy: 0.9044 - lr: 3.1623e-04\n",
      "Epoch 34/96\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.90444 to 0.90467, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.4900 - val_accuracy: 0.9047 - lr: 3.1623e-04\n",
      "Epoch 35/96\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.90467 to 0.90533, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.5067 - val_accuracy: 0.9053 - lr: 3.1623e-04\n",
      "Epoch 36/96\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.90533\n",
      "200/200 - 1s - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.5208 - val_accuracy: 0.9051 - lr: 3.1623e-04\n",
      "Epoch 37/96\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.90533 to 0.90556, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.5155 - val_accuracy: 0.9056 - lr: 3.1623e-04\n",
      "Epoch 38/96\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.90556\n",
      "200/200 - 1s - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.5334 - val_accuracy: 0.9042 - lr: 3.1623e-04\n",
      "Epoch 39/96\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.90556\n",
      "200/200 - 1s - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.5456 - val_accuracy: 0.9048 - lr: 3.1623e-04\n",
      "Epoch 40/96\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.90556\n",
      "200/200 - 1s - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.5685 - val_accuracy: 0.9042 - lr: 3.1623e-04\n",
      "Epoch 41/96\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.90556\n",
      "200/200 - 1s - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.5603 - val_accuracy: 0.9037 - lr: 3.1623e-04\n",
      "Epoch 42/96\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.90556\n",
      "200/200 - 1s - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.5760 - val_accuracy: 0.9048 - lr: 3.1623e-04\n",
      "Epoch 43/96\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.90556\n",
      "200/200 - 1s - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.6035 - val_accuracy: 0.9046 - lr: 3.1623e-04\n",
      "Epoch 44/96\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.90556\n",
      "200/200 - 1s - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.6112 - val_accuracy: 0.9034 - lr: 3.1623e-04\n",
      "Epoch 45/96\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.90556\n",
      "200/200 - 1s - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.6055 - val_accuracy: 0.9051 - lr: 3.1623e-04\n",
      "Epoch 46/96\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.90556\n",
      "200/200 - 1s - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.6328 - val_accuracy: 0.9038 - lr: 3.1623e-04\n",
      "Epoch 47/96\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00010000000639606199.\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.90556\n",
      "200/200 - 1s - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.6076 - val_accuracy: 0.9050 - lr: 3.1623e-04\n",
      "Epoch 48/96\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.90556\n",
      "200/200 - 1s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.6253 - val_accuracy: 0.9053 - lr: 1.0000e-04\n",
      "Epoch 49/96\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.90556\n",
      "200/200 - 1s - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.6360 - val_accuracy: 0.9049 - lr: 1.0000e-04\n",
      "Epoch 50/96\n",
      "\n",
      "Epoch 00050: val_accuracy improved from 0.90556 to 0.90600, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.0044 - accuracy: 0.9995 - val_loss: 0.6433 - val_accuracy: 0.9060 - lr: 1.0000e-04\n",
      "Epoch 51/96\n",
      "\n",
      "Epoch 00051: val_accuracy improved from 0.90600 to 0.90700, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.6494 - val_accuracy: 0.9070 - lr: 1.0000e-04\n",
      "Epoch 52/96\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.6533 - val_accuracy: 0.9068 - lr: 1.0000e-04\n",
      "Epoch 53/96\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.6551 - val_accuracy: 0.9060 - lr: 1.0000e-04\n",
      "Epoch 54/96\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.6654 - val_accuracy: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 55/96\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.6719 - val_accuracy: 0.9043 - lr: 1.0000e-04\n",
      "Epoch 56/96\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.6799 - val_accuracy: 0.9058 - lr: 1.0000e-04\n",
      "Epoch 57/96\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.6794 - val_accuracy: 0.9044 - lr: 1.0000e-04\n",
      "Epoch 58/96\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.6889 - val_accuracy: 0.9054 - lr: 1.0000e-04\n",
      "Epoch 59/96\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.6918 - val_accuracy: 0.9050 - lr: 1.0000e-04\n",
      "Epoch 60/96\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.6916 - val_accuracy: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 61/96\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.6983 - val_accuracy: 0.9051 - lr: 1.0000e-04\n",
      "Epoch 62/96\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.7090 - val_accuracy: 0.9062 - lr: 1.0000e-04\n",
      "Epoch 63/96\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.7167 - val_accuracy: 0.9039 - lr: 1.0000e-04\n",
      "Epoch 64/96\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.7217 - val_accuracy: 0.9054 - lr: 1.0000e-04\n",
      "Epoch 65/96\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.7324 - val_accuracy: 0.9054 - lr: 1.0000e-04\n",
      "Epoch 66/96\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.7352 - val_accuracy: 0.9039 - lr: 1.0000e-04\n",
      "Epoch 67/96\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.7505 - val_accuracy: 0.9033 - lr: 1.0000e-04\n",
      "Epoch 68/96\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.7475 - val_accuracy: 0.9050 - lr: 1.0000e-04\n",
      "Epoch 69/96\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.7593 - val_accuracy: 0.9061 - lr: 1.0000e-04\n",
      "Epoch 70/96\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7614 - val_accuracy: 0.9049 - lr: 1.0000e-04\n",
      "Epoch 71/96\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.7751 - val_accuracy: 0.9051 - lr: 1.0000e-04\n",
      "Epoch 72/96\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.7650 - val_accuracy: 0.9062 - lr: 1.0000e-04\n",
      "Epoch 73/96\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.7763 - val_accuracy: 0.9059 - lr: 1.0000e-04\n",
      "Epoch 74/96\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.7767 - val_accuracy: 0.9063 - lr: 1.0000e-04\n",
      "Epoch 75/96\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.7845 - val_accuracy: 0.9054 - lr: 1.0000e-04\n",
      "Epoch 76/96\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.7924 - val_accuracy: 0.9041 - lr: 1.0000e-04\n",
      "Epoch 77/96\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.9053 - lr: 1.0000e-04\n",
      "Epoch 78/96\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 8.9171e-04 - accuracy: 1.0000 - val_loss: 0.8146 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 79/96\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 8.5926e-04 - accuracy: 1.0000 - val_loss: 0.8119 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 80/96\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 7.5240e-04 - accuracy: 1.0000 - val_loss: 0.8234 - val_accuracy: 0.9056 - lr: 1.0000e-04\n",
      "Epoch 81/96\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 8.3371e-04 - accuracy: 1.0000 - val_loss: 0.8241 - val_accuracy: 0.9056 - lr: 1.0000e-04\n",
      "Epoch 82/96\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 8.0571e-04 - accuracy: 1.0000 - val_loss: 0.8261 - val_accuracy: 0.9059 - lr: 1.0000e-04\n",
      "Epoch 83/96\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 6.9033e-04 - accuracy: 1.0000 - val_loss: 0.8461 - val_accuracy: 0.9060 - lr: 1.0000e-04\n",
      "Epoch 84/96\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.8425 - val_accuracy: 0.9029 - lr: 1.0000e-04\n",
      "Epoch 85/96\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.8267 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 86/96\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 8.0352e-04 - accuracy: 1.0000 - val_loss: 0.8323 - val_accuracy: 0.9057 - lr: 1.0000e-04\n",
      "Epoch 87/96\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 5.8497e-04 - accuracy: 1.0000 - val_loss: 0.8430 - val_accuracy: 0.9044 - lr: 1.0000e-04\n",
      "Epoch 88/96\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 5.1593e-04 - accuracy: 1.0000 - val_loss: 0.8504 - val_accuracy: 0.9050 - lr: 1.0000e-04\n",
      "Epoch 89/96\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 5.0048e-04 - accuracy: 1.0000 - val_loss: 0.8549 - val_accuracy: 0.9050 - lr: 1.0000e-04\n",
      "Epoch 90/96\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 4.6405e-04 - accuracy: 1.0000 - val_loss: 0.8597 - val_accuracy: 0.9050 - lr: 1.0000e-04\n",
      "Epoch 91/96\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 4.4784e-04 - accuracy: 1.0000 - val_loss: 0.8663 - val_accuracy: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 92/96\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 4.3204e-04 - accuracy: 1.0000 - val_loss: 0.8732 - val_accuracy: 0.9051 - lr: 1.0000e-04\n",
      "Epoch 93/96\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 4.3232e-04 - accuracy: 1.0000 - val_loss: 0.8747 - val_accuracy: 0.9046 - lr: 1.0000e-04\n",
      "Epoch 94/96\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 4.3372e-04 - accuracy: 1.0000 - val_loss: 0.8808 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 95/96\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 4.1283e-04 - accuracy: 1.0000 - val_loss: 0.8839 - val_accuracy: 0.9056 - lr: 1.0000e-04\n",
      "Epoch 96/96\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.90700\n",
      "200/200 - 1s - loss: 4.1719e-04 - accuracy: 1.0000 - val_loss: 0.8886 - val_accuracy: 0.9036 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = pruned_model.fit(X_train, \n",
    "               y_train,\n",
    "               epochs=epochs, batch_size=batch_size, \n",
    "              validation_data = (X_val, y_val),\n",
    "               verbose=2, \n",
    "                    shuffle = True,\n",
    "                           callbacks=get_prunned_callbacks('mlp.mnist.sparse_train.hdf5')\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8886192440986633, 0.9035555720329285]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model.evaluate(X_val, y_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6493906378746033, 0.9070000052452087]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7239408493041992, 0.9039000272750854]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model.load_weights('mlp.mnist.sparse_train.hdf5')\n",
    "print(pruned_model.evaluate(X_val, y_val, verbose=0))\n",
    "pruned_model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check original mask equals prunned model mask after trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_low_magnitude_hidden_1: True, shape: (784, 1568), sparcity: 0.5\n",
      "prune_low_magnitude_hidden_2: True, shape: (1568, 784), sparcity: 0.5\n",
      "prune_low_magnitude_Salida: True, shape: (784, 10), sparcity: 0.5\n"
     ]
    }
   ],
   "source": [
    "lth.verify_mask_with_model_min_weights(pruned_model, model_pruned_layers_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 842us/step - loss: 0.4112 - accuracy: 0.8986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4111524820327759, 0.8985999822616577]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pruned_layers_trained.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 905us/step - loss: 0.7239 - accuracy: 0.9039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7239408493041992, 0.9039000272750854]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-train reducing pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model_2 = lth.initialize_sparse_model('mlp.mnist.initial_weights.hdf5', pruned_model, pm**(1/2))\n",
    "lth.compile_model(pruned_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/96\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.84722, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.4508 - accuracy: 0.8435 - val_loss: 0.4168 - val_accuracy: 0.8472 - lr: 0.0010\n",
      "Epoch 2/96\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.84722 to 0.87578, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.3223 - accuracy: 0.8815 - val_loss: 0.3429 - val_accuracy: 0.8758 - lr: 0.0010\n",
      "Epoch 3/96\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.87578\n",
      "200/200 - 1s - loss: 0.2888 - accuracy: 0.8916 - val_loss: 0.3647 - val_accuracy: 0.8614 - lr: 0.0010\n",
      "Epoch 4/96\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.87578 to 0.88133, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.2707 - accuracy: 0.8994 - val_loss: 0.3225 - val_accuracy: 0.8813 - lr: 0.0010\n",
      "Epoch 5/96\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.88133\n",
      "200/200 - 1s - loss: 0.2510 - accuracy: 0.9058 - val_loss: 0.3323 - val_accuracy: 0.8758 - lr: 0.0010\n",
      "Epoch 6/96\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.88133 to 0.88833, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.2419 - accuracy: 0.9090 - val_loss: 0.3130 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Epoch 7/96\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.88833\n",
      "200/200 - 1s - loss: 0.2250 - accuracy: 0.9143 - val_loss: 0.3311 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Epoch 8/96\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.88833\n",
      "200/200 - 1s - loss: 0.2197 - accuracy: 0.9171 - val_loss: 0.3243 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Epoch 9/96\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.88833\n",
      "200/200 - 1s - loss: 0.2041 - accuracy: 0.9218 - val_loss: 0.3255 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Epoch 10/96\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.88833 to 0.88922, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.2015 - accuracy: 0.9241 - val_loss: 0.3547 - val_accuracy: 0.8892 - lr: 0.0010\n",
      "Epoch 11/96\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.88922 to 0.89567, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.1888 - accuracy: 0.9285 - val_loss: 0.3057 - val_accuracy: 0.8957 - lr: 0.0010\n",
      "Epoch 12/96\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.89567\n",
      "200/200 - 1s - loss: 0.1848 - accuracy: 0.9299 - val_loss: 0.3317 - val_accuracy: 0.8888 - lr: 0.0010\n",
      "Epoch 13/96\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.89567\n",
      "200/200 - 1s - loss: 0.1732 - accuracy: 0.9338 - val_loss: 0.3184 - val_accuracy: 0.8912 - lr: 0.0010\n",
      "Epoch 14/96\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.89567\n",
      "200/200 - 1s - loss: 0.1724 - accuracy: 0.9347 - val_loss: 0.3219 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Epoch 15/96\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.89567\n",
      "200/200 - 1s - loss: 0.1576 - accuracy: 0.9400 - val_loss: 0.3375 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Epoch 16/96\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.89567 to 0.89644, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.1577 - accuracy: 0.9397 - val_loss: 0.3315 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 17/96\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.89644\n",
      "200/200 - 1s - loss: 0.1505 - accuracy: 0.9422 - val_loss: 0.3390 - val_accuracy: 0.8914 - lr: 0.0010\n",
      "Epoch 18/96\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.89644\n",
      "200/200 - 1s - loss: 0.1467 - accuracy: 0.9430 - val_loss: 0.3543 - val_accuracy: 0.8914 - lr: 0.0010\n",
      "Epoch 19/96\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.89644\n",
      "200/200 - 1s - loss: 0.1398 - accuracy: 0.9463 - val_loss: 0.3715 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 20/96\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.89644\n",
      "200/200 - 1s - loss: 0.1332 - accuracy: 0.9491 - val_loss: 0.3683 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Epoch 21/96\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.89644\n",
      "200/200 - 1s - loss: 0.1315 - accuracy: 0.9490 - val_loss: 0.3602 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 22/96\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.89644 to 0.90111, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.1208 - accuracy: 0.9536 - val_loss: 0.3601 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 23/96\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.90111\n",
      "200/200 - 1s - loss: 0.1186 - accuracy: 0.9544 - val_loss: 0.3746 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 24/96\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.90111\n",
      "200/200 - 1s - loss: 0.1129 - accuracy: 0.9561 - val_loss: 0.3825 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 25/96\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.90111\n",
      "200/200 - 1s - loss: 0.1145 - accuracy: 0.9555 - val_loss: 0.3790 - val_accuracy: 0.8894 - lr: 0.0010\n",
      "Epoch 26/96\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.90111\n",
      "200/200 - 1s - loss: 0.1097 - accuracy: 0.9577 - val_loss: 0.3997 - val_accuracy: 0.8864 - lr: 0.0010\n",
      "Epoch 27/96\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.90111\n",
      "200/200 - 1s - loss: 0.1082 - accuracy: 0.9578 - val_loss: 0.4056 - val_accuracy: 0.8944 - lr: 0.0010\n",
      "Epoch 28/96\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.90111\n",
      "200/200 - 1s - loss: 0.1000 - accuracy: 0.9621 - val_loss: 0.3945 - val_accuracy: 0.8978 - lr: 0.0010\n",
      "Epoch 29/96\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.90111\n",
      "200/200 - 1s - loss: 0.0922 - accuracy: 0.9638 - val_loss: 0.4136 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Epoch 30/96\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.90111\n",
      "200/200 - 1s - loss: 0.0931 - accuracy: 0.9635 - val_loss: 0.4254 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 31/96\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.90111\n",
      "200/200 - 1s - loss: 0.0871 - accuracy: 0.9669 - val_loss: 0.4603 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Epoch 32/96\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00031622778103685084.\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.90111\n",
      "200/200 - 1s - loss: 0.0886 - accuracy: 0.9651 - val_loss: 0.4181 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Epoch 33/96\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.90111 to 0.90789, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.0524 - accuracy: 0.9811 - val_loss: 0.4128 - val_accuracy: 0.9079 - lr: 3.1623e-04\n",
      "Epoch 34/96\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0432 - accuracy: 0.9843 - val_loss: 0.4320 - val_accuracy: 0.9049 - lr: 3.1623e-04\n",
      "Epoch 35/96\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0400 - accuracy: 0.9855 - val_loss: 0.4470 - val_accuracy: 0.9059 - lr: 3.1623e-04\n",
      "Epoch 36/96\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0383 - accuracy: 0.9863 - val_loss: 0.4529 - val_accuracy: 0.9028 - lr: 3.1623e-04\n",
      "Epoch 37/96\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0354 - accuracy: 0.9879 - val_loss: 0.4589 - val_accuracy: 0.9053 - lr: 3.1623e-04\n",
      "Epoch 38/96\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0332 - accuracy: 0.9882 - val_loss: 0.4653 - val_accuracy: 0.9039 - lr: 3.1623e-04\n",
      "Epoch 39/96\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0316 - accuracy: 0.9890 - val_loss: 0.4892 - val_accuracy: 0.9036 - lr: 3.1623e-04\n",
      "Epoch 40/96\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0288 - accuracy: 0.9904 - val_loss: 0.5171 - val_accuracy: 0.9048 - lr: 3.1623e-04\n",
      "Epoch 41/96\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0294 - accuracy: 0.9899 - val_loss: 0.5105 - val_accuracy: 0.9033 - lr: 3.1623e-04\n",
      "Epoch 42/96\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.5268 - val_accuracy: 0.9033 - lr: 3.1623e-04\n",
      "Epoch 43/96\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00010000000639606199.\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0250 - accuracy: 0.9917 - val_loss: 0.5559 - val_accuracy: 0.9020 - lr: 3.1623e-04\n",
      "Epoch 44/96\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0175 - accuracy: 0.9953 - val_loss: 0.5496 - val_accuracy: 0.9066 - lr: 1.0000e-04\n",
      "Epoch 45/96\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.5542 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
      "Epoch 46/96\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.5649 - val_accuracy: 0.9079 - lr: 1.0000e-04\n",
      "Epoch 47/96\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.5651 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 48/96\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.5716 - val_accuracy: 0.9047 - lr: 1.0000e-04\n",
      "Epoch 49/96\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.5770 - val_accuracy: 0.9036 - lr: 1.0000e-04\n",
      "Epoch 50/96\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.5834 - val_accuracy: 0.9059 - lr: 1.0000e-04\n",
      "Epoch 51/96\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.5875 - val_accuracy: 0.9060 - lr: 1.0000e-04\n",
      "Epoch 52/96\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.5983 - val_accuracy: 0.9056 - lr: 1.0000e-04\n",
      "Epoch 53/96\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.6005 - val_accuracy: 0.9076 - lr: 1.0000e-04\n",
      "Epoch 54/96\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0107 - accuracy: 0.9978 - val_loss: 0.6112 - val_accuracy: 0.9047 - lr: 1.0000e-04\n",
      "Epoch 55/96\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.6211 - val_accuracy: 0.9050 - lr: 1.0000e-04\n",
      "Epoch 56/96\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0097 - accuracy: 0.9981 - val_loss: 0.6265 - val_accuracy: 0.9039 - lr: 1.0000e-04\n",
      "Epoch 57/96\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.6356 - val_accuracy: 0.9038 - lr: 1.0000e-04\n",
      "Epoch 58/96\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.6389 - val_accuracy: 0.9057 - lr: 1.0000e-04\n",
      "Epoch 59/96\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0085 - accuracy: 0.9986 - val_loss: 0.6330 - val_accuracy: 0.9059 - lr: 1.0000e-04\n",
      "Epoch 60/96\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.6491 - val_accuracy: 0.9044 - lr: 1.0000e-04\n",
      "Epoch 61/96\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.6570 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 62/96\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.6687 - val_accuracy: 0.9046 - lr: 1.0000e-04\n",
      "Epoch 63/96\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.6715 - val_accuracy: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 64/96\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.6888 - val_accuracy: 0.9038 - lr: 1.0000e-04\n",
      "Epoch 65/96\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.6812 - val_accuracy: 0.9040 - lr: 1.0000e-04\n",
      "Epoch 66/96\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.6955 - val_accuracy: 0.9054 - lr: 1.0000e-04\n",
      "Epoch 67/96\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.7116 - val_accuracy: 0.9039 - lr: 1.0000e-04\n",
      "Epoch 68/96\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.7104 - val_accuracy: 0.9057 - lr: 1.0000e-04\n",
      "Epoch 69/96\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.7200 - val_accuracy: 0.9063 - lr: 1.0000e-04\n",
      "Epoch 70/96\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.7204 - val_accuracy: 0.9053 - lr: 1.0000e-04\n",
      "Epoch 71/96\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.7295 - val_accuracy: 0.9061 - lr: 1.0000e-04\n",
      "Epoch 72/96\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.7409 - val_accuracy: 0.9051 - lr: 1.0000e-04\n",
      "Epoch 73/96\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.7451 - val_accuracy: 0.9032 - lr: 1.0000e-04\n",
      "Epoch 74/96\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.7564 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 75/96\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.7522 - val_accuracy: 0.9059 - lr: 1.0000e-04\n",
      "Epoch 76/96\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.7682 - val_accuracy: 0.9044 - lr: 1.0000e-04\n",
      "Epoch 77/96\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.7709 - val_accuracy: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 78/96\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.7761 - val_accuracy: 0.9044 - lr: 1.0000e-04\n",
      "Epoch 79/96\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.7877 - val_accuracy: 0.9043 - lr: 1.0000e-04\n",
      "Epoch 80/96\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.7804 - val_accuracy: 0.9060 - lr: 1.0000e-04\n",
      "Epoch 81/96\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.8016 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
      "Epoch 82/96\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.7880 - val_accuracy: 0.9053 - lr: 1.0000e-04\n",
      "Epoch 83/96\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.8039 - val_accuracy: 0.9059 - lr: 1.0000e-04\n",
      "Epoch 84/96\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.8145 - val_accuracy: 0.9062 - lr: 1.0000e-04\n",
      "Epoch 85/96\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.8258 - val_accuracy: 0.9061 - lr: 1.0000e-04\n",
      "Epoch 86/96\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.8316 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 87/96\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.8480 - val_accuracy: 0.9061 - lr: 1.0000e-04\n",
      "Epoch 88/96\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8496 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 89/96\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8611 - val_accuracy: 0.9040 - lr: 1.0000e-04\n",
      "Epoch 90/96\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.8680 - val_accuracy: 0.9036 - lr: 1.0000e-04\n",
      "Epoch 91/96\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.8581 - val_accuracy: 0.9070 - lr: 1.0000e-04\n",
      "Epoch 92/96\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.8721 - val_accuracy: 0.9054 - lr: 1.0000e-04\n",
      "Epoch 93/96\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.8850 - val_accuracy: 0.9038 - lr: 1.0000e-04\n",
      "Epoch 94/96\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.8908 - val_accuracy: 0.9041 - lr: 1.0000e-04\n",
      "Epoch 95/96\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.8937 - val_accuracy: 0.9043 - lr: 1.0000e-04\n",
      "Epoch 96/96\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.90789\n",
      "200/200 - 1s - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.8820 - val_accuracy: 0.9036 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = pruned_model_2.fit(X_train, \n",
    "               y_train,\n",
    "               epochs=epochs, batch_size=batch_size, \n",
    "              validation_data = (X_val, y_val),\n",
    "               verbose=2, \n",
    "                    shuffle = True,\n",
    "                           callbacks=get_prunned_callbacks('mlp.mnist.sparse_train.hdf5')\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41279926896095276, 0.9078888893127441]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4661621153354645, 0.9016000032424927]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model.load_weights('mlp.mnist.sparse_train.hdf5')\n",
    "print(pruned_model.evaluate(X_val, y_val, verbose=0))\n",
    "pruned_model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

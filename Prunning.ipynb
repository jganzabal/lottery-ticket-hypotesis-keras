{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -q tensorflow-model-optimization\n",
    "#! pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LTH_helper import LTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1803.03635\n",
    "\n",
    "https://www.youtube.com/watch?v=0VH1Lim8gL8&feature=youtu.be&t=2760"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "import os\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    np.random.seed(seed)\n",
    "    rn.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    # session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    # sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    # K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21a1ba1a316bb0a6f5d8f85d86b3ba2307f125af"
   },
   "source": [
    "# Cargo datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "7720949cd52b1de2d7687500e3d121f30bc80f82"
   },
   "outputs": [],
   "source": [
    "X = np.load(folder+'train_images.npy').reshape(-1, 784)/255\n",
    "y = np.loadtxt(folder+'train_labels.csv', delimiter=',', skiprows=1).reshape(-1, 1)\n",
    "X_test = np.load(folder+'test_images.npy').reshape(-1, 784)/255\n",
    "y_test = pd.read_csv(folder+'test_labels.csv')['Category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f987cc26468c6d17e63a953827437abb66da4383"
   },
   "source": [
    "# Red neuronal b√°sica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, lr=0.001):\n",
    "    optim = optimizers.Adam(lr=lr)\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "6e998b9f383e967a21d0ee6a89dfc8fec72d7f80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_1 (Dense)             (None, 1568)              1230880   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "hidden_2 (Dense)             (None, 784)               1230096   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Salida (Dense)               (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,468,826\n",
      "Trainable params: 2,468,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(compile_model_flag=True, lr=0.001):\n",
    "    input_dim=784\n",
    "    output_size = 10\n",
    "    # Creo el modelo\n",
    "    model = Sequential()\n",
    "    model.add(Dense(784*2, activation='linear', name='hidden_1', input_dim=input_dim))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(784, activation='linear', name='hidden_2'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(output_size, name='Salida'))\n",
    "    model.add(Activation('softmax'))\n",
    "    if compile_model_flag:\n",
    "        compile_model(model, lr=lr)\n",
    "    return model\n",
    "model = get_model()\n",
    "# model.save_weights('random-init.hdf5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lth = LTH(get_model, compile_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(filename):\n",
    "    return [\n",
    "        ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=np.sqrt(0.1), patience=10, verbose=1, min_lr=1e-4),\n",
    "        ModelCheckpoint(filepath=filename,  verbose=1, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "bac8f7a2f7fb157ec21445359a6f316073515ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.84911, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.5009 - accuracy: 0.8201 - val_loss: 0.4079 - val_accuracy: 0.8491 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.84911 to 0.86822, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.3495 - accuracy: 0.8727 - val_loss: 0.3543 - val_accuracy: 0.8682 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.86822\n",
      "200/200 - 1s - loss: 0.3133 - accuracy: 0.8828 - val_loss: 0.3611 - val_accuracy: 0.8644 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.86822 to 0.88044, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.2899 - accuracy: 0.8921 - val_loss: 0.3233 - val_accuracy: 0.8804 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.88044 to 0.88200, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.2698 - accuracy: 0.9005 - val_loss: 0.3233 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.88200\n",
      "200/200 - 0s - loss: 0.2573 - accuracy: 0.9043 - val_loss: 0.3259 - val_accuracy: 0.8803 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.88200 to 0.88511, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 0s - loss: 0.2439 - accuracy: 0.9092 - val_loss: 0.3147 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.88511\n",
      "200/200 - 0s - loss: 0.2329 - accuracy: 0.9120 - val_loss: 0.3290 - val_accuracy: 0.8827 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.88511 to 0.88922, saving model to mlp.mnist.first_train.hdf5\n",
      "200/200 - 1s - loss: 0.2209 - accuracy: 0.9159 - val_loss: 0.3137 - val_accuracy: 0.8892 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.88922\n",
      "200/200 - 0s - loss: 0.2154 - accuracy: 0.9174 - val_loss: 0.3346 - val_accuracy: 0.8874 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "set_random_seeds(42)\n",
    "model = get_model()\n",
    "\n",
    "# Save initial weights\n",
    "model.save_weights('mlp.mnist.initial_weights.hdf5')\n",
    "history = model.fit(X_train, \n",
    "           y_train,\n",
    "           epochs=epochs, batch_size=batch_size, \n",
    "           validation_data = (X_val, y_val),\n",
    "           verbose=2, \n",
    "           callbacks=get_callbacks('mlp.mnist.first_train.hdf5')\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3346378207206726, 0.8874444365501404]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val, y_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3136780261993408, 0.8892222046852112] [0.32768240571022034, 0.8866999745368958]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('mlp.mnist.first_train.hdf5')\n",
    "print(model.evaluate(X_val, y_val, verbose=0), model.evaluate(X_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pm**(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hidden_1', 'activation_3', 'hidden_2', 'activation_4', 'Salida', 'activation_5']\n"
     ]
    }
   ],
   "source": [
    "print([layer.name for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/usuario/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:199: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "layers_to_pune = ['hidden_1', 'hidden_2', 'Salida']\n",
    "model_pruned_layers_trained = lth.get_prunned_model('mlp.mnist.first_train.hdf5', layers_to_pune, X_train, y_train, pm = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 806us/step - loss: 0.5985 - accuracy: 0.8304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5985085368156433, 0.8303999900817871]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pruned_layers_trained.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 841us/step - loss: 0.5985 - accuracy: 0.8304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5985085368156433, 0.8303999900817871]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_initialized = lth.initialize_sparse_model('mlp.mnist.first_train.hdf5', model_pruned_layers_trained)\n",
    "model_initialized.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_low_magnitude_hidden_1: True, shape: (784, 1568), sparcity: 0.8000003253852561\n",
      "prune_low_magnitude_hidden_2: True, shape: (1568, 784), sparcity: 0.8000003253852561\n",
      "prune_low_magnitude_Salida: True, shape: (784, 10), sparcity: 0.8\n"
     ]
    }
   ],
   "source": [
    "lth.verify_mask_with_model_min_weights('mlp.mnist.first_train.hdf5', model_pruned_layers_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_low_magnitude_hidden_1: False, shape: (784, 1568), sparcity: 0.8000003253852561\n",
      "prune_low_magnitude_hidden_2: False, shape: (1568, 784), sparcity: 0.8000003253852561\n",
      "prune_low_magnitude_Salida: False, shape: (784, 10), sparcity: 0.8\n"
     ]
    }
   ],
   "source": [
    "# It has to be false beacuase the model is not trained\n",
    "lth.verify_mask_with_model_min_weights('mlp.mnist.initial_weights.hdf5', model_pruned_layers_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize prunned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = lth.initialize_sparse_model('mlp.mnist.initial_weights.hdf5', model_pruned_layers_trained)\n",
    "lth.compile_model(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_low_magnitude_hidden_1: True, shape: (784, 1568), sparcity: 0.8000003253852561\n",
      "prune_low_magnitude_hidden_2: True, shape: (1568, 784), sparcity: 0.8000003253852561\n",
      "prune_low_magnitude_Salida: True, shape: (784, 10), sparcity: 0.8\n"
     ]
    }
   ],
   "source": [
    "lth.verify_mask_with_model_min_weights(pruned_model, model_pruned_layers_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train prunned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=np.sqrt(0.1), patience=10, verbose=1),\n",
    "    ModelCheckpoint(filepath=f'mlp.mnist_no_kfold_sparse.hdf5', verbose=1, save_best_only=True, monitor='val_accuracy', mode='auto'),\n",
    "   # tfmot.sparsity.keras.PruningSummaries(log_dir='logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.87011, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.4811 - accuracy: 0.8490 - val_loss: 0.3529 - val_accuracy: 0.8701 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.87011 to 0.88711, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.2973 - accuracy: 0.8907 - val_loss: 0.3112 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.88711 to 0.89300, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.2545 - accuracy: 0.9061 - val_loss: 0.2982 - val_accuracy: 0.8930 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.89300\n",
      "200/200 - 1s - loss: 0.2334 - accuracy: 0.9134 - val_loss: 0.2996 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.89300 to 0.89789, saving model to mlp.mnist.sparse_train.hdf5\n",
      "200/200 - 1s - loss: 0.2145 - accuracy: 0.9203 - val_loss: 0.2865 - val_accuracy: 0.8979 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.89789\n",
      "200/200 - 1s - loss: 0.1998 - accuracy: 0.9249 - val_loss: 0.3116 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.89789\n",
      "200/200 - 1s - loss: 0.1882 - accuracy: 0.9298 - val_loss: 0.2927 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.89789\n",
      "200/200 - 1s - loss: 0.1763 - accuracy: 0.9340 - val_loss: 0.2951 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.89789\n",
      "200/200 - 1s - loss: 0.1660 - accuracy: 0.9381 - val_loss: 0.3004 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.89789\n",
      "200/200 - 1s - loss: 0.1569 - accuracy: 0.9415 - val_loss: 0.3075 - val_accuracy: 0.8969 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = pruned_model.fit(X_train, \n",
    "               y_train,\n",
    "               epochs=epochs, batch_size=batch_size, \n",
    "              validation_data = (X_val, y_val),\n",
    "               verbose=2, \n",
    "                    shuffle = True,\n",
    "                           callbacks=get_callbacks('mlp.mnist.sparse_train.hdf5') + [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3075350821018219, 0.8968889117240906]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model.evaluate(X_val, y_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28652212023735046, 0.8978888988494873]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.307934045791626, 0.8906999826431274]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model.load_weights('mlp.mnist.sparse_train.hdf5')\n",
    "print(pruned_model.evaluate(X_val, y_val, verbose=0))\n",
    "pruned_model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check original mask equals prunned model mask after trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_low_magnitude_hidden_1: True, shape: (784, 1568), sparcity: 0.8000003253852561\n",
      "prune_low_magnitude_hidden_2: True, shape: (1568, 784), sparcity: 0.8000003253852561\n",
      "prune_low_magnitude_Salida: True, shape: (784, 10), sparcity: 0.8\n"
     ]
    }
   ],
   "source": [
    "lth.verify_mask_with_model_min_weights(pruned_model, model_pruned_layers_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 852us/step - loss: 0.5985 - accuracy: 0.8304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5985085368156433, 0.8303999900817871]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pruned_layers_trained.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 956us/step - loss: 0.3079 - accuracy: 0.8907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.307934045791626, 0.8906999826431274]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
